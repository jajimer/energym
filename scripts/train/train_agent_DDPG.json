
{
    "id": "DDPGExperimentExample",
    "environment": "Eplus-5zone-hot-continuous-stochastic-v1",
    "episodes": 5,
    "algorithm": {
        "name": "SB3-DDPG",
        "log_interval": 1,
        "parameters": {
            "policy": "MlpPolicy",
            "learning_rate": 1e-3,
            "buffer_size": 1000000,
            "learning_starts": 100,
            "batch_size": 100,
            "tau": 0.005,
            "gamma": 0.99,
            "train_freq": [1, "episode"],
            "gradient_steps": -1,
            "action_noise": null,
            "replay_buffer_class": null,
            "replay_buffer_kwargs": null,
            "optimize_memory_usage": false,
            "tensorboard_log": null,
            "policy_kwargs": null,
            "verbose": 0,
            "seed": null,
            "device": "auto",
            "_init_setup_model": true
        }
    },
    "env_params": {
        "reward": "LinearReward"
    },
    "seed": 3,
    "model": null,
    "wrappers": {
        "NormalizeAction": {},
        "NormalizeObservation": {},
        "LoggerWrapper": {
            "logger_class": "sinergym.utils.logger.Logger"
        },
        "CSVLogger": {}
    },
    "evaluation": {
        "eval_freq": 2,
        "eval_length": 1
    }
}
