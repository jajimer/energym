{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "# Rule Controller example"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "First, we import all the necessary libraries. Remember to always import `sinergym`, even if it appears unused, as it's needed to define the environments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "from typing import List, Any, Sequence\n",
                "from sinergym.utils.constants import YEAR\n",
                "from datetime import datetime\n",
                "import gymnasium as gym\n",
                "import numpy as np\n",
                "import sinergym"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "Next, we can define the environment we want to use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "#==============================================================================================#\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment... [5zone-hot-continuous-v1]\u001b[0m\n",
                        "#==============================================================================================#\n",
                        "\u001b[38;20m[MODELING] (INFO) : Experiment working directory created [/workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res1]\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Model Config is correct.\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Variable available names\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Meter available names\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : runperiod established: {'start_day': 1, 'start_month': 1, 'start_year': 1991, 'end_day': 31, 'end_month': 12, 'end_year': 1991, 'start_weekday': 0, 'n_steps_per_hour': 4}\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : timesteps per episode: 35041\u001b[0m\n",
                        "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment 5zone-hot-continuous-v1 created successfully.\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "env = gym.make('Eplus-5zone-hot-continuous-v1')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "For the Rule-based controller, check out the already defined controllers. There's one for each building. We're extending that controller and defining the action function we want. Feel free to modify the function to define your own action."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "from sinergym.utils.controllers import RBC5Zone\n",
                "\n",
                "class MyRuleBasedController(RBC5Zone):\n",
                "\n",
                "    def act(self, observation: List[Any]) -> Sequence[Any]:\n",
                "        \"\"\"Select action based on outdoor air drybulb temperature and daytime.\n",
                "\n",
                "        Args:\n",
                "            observation (List[Any]): Perceived observation.\n",
                "\n",
                "        Returns:\n",
                "            Sequence[Any]: Action chosen.\n",
                "        \"\"\"\n",
                "        obs_dict = dict(zip(self.env.get_wrapper_attr('observation_variables'), observation))\n",
                "\n",
                "        out_temp = obs_dict['outdoor_temperature']\n",
                "\n",
                "        day = int(obs_dict['day_of_month'])\n",
                "        month = int(obs_dict['month'])\n",
                "        hour = int(obs_dict['hour'])\n",
                "        year = int(obs_dict['year'] if obs_dict.get('year',False) else YEAR)\n",
                "\n",
                "        summer_start_date = datetime(year, 6, 1)\n",
                "        summer_final_date = datetime(year, 9, 30)\n",
                "\n",
                "        current_dt = datetime(year, month, day)\n",
                "\n",
                "        # Get season comfort range\n",
                "        if current_dt >= summer_start_date and current_dt <= summer_final_date:\n",
                "            season_comfort_range = self.setpoints_summer\n",
                "        else:\n",
                "            season_comfort_range = self.setpoints_summer\n",
                "        season_comfort_range = self.setpoints_winter\n",
                "        # Update setpoints\n",
                "        in_temp = obs_dict['air_temperature']\n",
                "\n",
                "        current_heat_setpoint = obs_dict[\n",
                "            'htg_setpoint']\n",
                "        current_cool_setpoint = obs_dict[\n",
                "            'clg_setpoint']\n",
                "\n",
                "        new_heat_setpoint = current_heat_setpoint\n",
                "        new_cool_setpoint = current_cool_setpoint\n",
                "\n",
                "        if in_temp < season_comfort_range[0]:\n",
                "            new_heat_setpoint = current_heat_setpoint + 1\n",
                "            new_cool_setpoint = current_cool_setpoint + 1\n",
                "        elif in_temp > season_comfort_range[1]:\n",
                "            new_cool_setpoint = current_cool_setpoint - 1\n",
                "            new_heat_setpoint = current_heat_setpoint - 1\n",
                "\n",
                "        #Clip setpoints to the action space\n",
                "        if new_heat_setpoint>self.env.get_wrapper_attr('action_space').high[0]:\n",
                "            new_heat_setpoint=self.env.get_wrapper_attr('action_space').high[0]\n",
                "        if new_heat_setpoint<self.env.get_wrapper_attr('action_space').low[0]:\n",
                "            new_heat_setpoint=self.env.get_wrapper_attr('action_space').low[0]\n",
                "        if new_cool_setpoint>self.env.get_wrapper_attr('action_space').high[1]:\n",
                "            new_cool_setpoint=self.env.get_wrapper_attr('action_space').high[1]\n",
                "        if new_cool_setpoint<self.env.get_wrapper_attr('action_space').low[1]:\n",
                "            new_cool_setpoint=self.env.get_wrapper_attr('action_space').low[1]\n",
                "\n",
                "        action = (new_heat_setpoint, new_cool_setpoint)\n",
                "        if current_dt.weekday() > 5 or hour in range(22, 6):\n",
                "            #weekend or night\n",
                "            action = (18.33, 23.33)\n",
                "\n",
                "        return action"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "Now that our controller is ready, we can use it:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "#----------------------------------------------------------------------------------------------#\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode... [5zone-hot-continuous-v1] [Episode 1]\u001b[0m\n",
                        "#----------------------------------------------------------------------------------------------#\n",
                        "\u001b[38;20m[MODELING] (INFO) : Episode directory created [/workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res1/Eplus-env-sub_run1]\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model. [USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw]\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path... [/workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res1/Eplus-env-sub_run1/output]\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : Running EnergyPlus with args: ['-w', '/workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res1/Eplus-env-sub_run1/USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw', '-d', '/workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res1/Eplus-env-sub_run1/output', '/workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res1/Eplus-env-sub_run1/5ZoneAutoDXVAV.epJSON']\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
                        "Reward:  -0.10122987987606541 {'time_elapsed(hours)': 0.5, 'month': 1, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(13.8), np.float32(30.0)), 'timestep': 2, 'reward': -0.10122987987606541, 'energy_term': -0.00589738497079933, 'comfort_term': -0.09533249490526607, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': -0.19066498981053215, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.19066498981053215}\n",
                        "Progress: |*--------------------------------------------------------------------------------------------------| 1%\r"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.12/dist-packages/gymnasium/spaces/box.py:240: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
                        "  gym.logger.warn(\"Casting input x to numpy array.\")\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Reward:  -504.21870953491435 {'time_elapsed(hours)': 744.25, 'month': 2, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 2977, 'reward': -0.00589738497079933, 'energy_term': -0.00589738497079933, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': 0, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.0}\n",
                        "Reward:  -774.6506450262573 {'time_elapsed(hours)': 1416.25, 'month': 3, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 5665, 'reward': -0.00589738497079933, 'energy_term': -0.00589738497079933, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': 0, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.0}\n",
                        "Reward:  -1103.0703996019445 {'time_elapsed(hours)': 2160.25, 'month': 4, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (18.33, 23.33), 'timestep': 8641, 'reward': -0.00589738497079933, 'energy_term': -0.00589738497079933, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': 0, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.0}\n",
                        "Reward:  -1447.3921219019942 {'time_elapsed(hours)': 2880.25, 'month': 5, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 11521, 'reward': -0.00986244334034497, 'energy_term': -0.00986244334034497, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -197.24886680689937, 'abs_comfort_penalty': 0, 'total_power_demand': 197.24886680689937, 'total_temperature_violation': 0.0}\n",
                        "Reward:  -1853.7866003435856 {'time_elapsed(hours)': 3624.25, 'month': 6, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 14497, 'reward': -0.4434189735777289, 'energy_term': -0.033067592973972056, 'comfort_term': -0.41035138060375687, 'reward_weight': 0.5, 'abs_energy_penalty': -661.351859479441, 'abs_comfort_penalty': -0.8207027612075137, 'total_power_demand': 661.351859479441, 'total_temperature_violation': 0.8207027612075137}\n",
                        "Reward:  -2998.2239338784507 {'time_elapsed(hours)': 4344.25, 'month': 7, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (18.33, 23.33), 'timestep': 17377, 'reward': -0.2168368480281406, 'energy_term': -0.033314504940077795, 'comfort_term': -0.1835223430880628, 'reward_weight': 0.5, 'abs_energy_penalty': -666.2900988015559, 'abs_comfort_penalty': -0.3670446861761256, 'total_power_demand': 666.2900988015559, 'total_temperature_violation': 0.3670446861761256}\n",
                        "Reward:  -4196.246113755758 {'time_elapsed(hours)': 5088.25, 'month': 8, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 20353, 'reward': -0.44442655802186126, 'energy_term': -0.036554511691237274, 'comfort_term': -0.407872046330624, 'reward_weight': 0.5, 'abs_energy_penalty': -731.0902338247454, 'abs_comfort_penalty': -0.815744092661248, 'total_power_demand': 731.0902338247454, 'total_temperature_violation': 0.815744092661248}\n",
                        "Reward:  -5384.344180052351 {'time_elapsed(hours)': 5832.25, 'month': 9, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 23329, 'reward': -0.2973068555116624, 'energy_term': -0.029937333487440796, 'comfort_term': -0.2673695220242216, 'reward_weight': 0.5, 'abs_energy_penalty': -598.7466697488159, 'abs_comfort_penalty': -0.5347390440484432, 'total_power_demand': 598.7466697488159, 'total_temperature_violation': 0.5347390440484432}\n",
                        "Reward:  -6630.526627252363 {'time_elapsed(hours)': 6552.25, 'month': 10, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 26209, 'reward': -0.0317703779388386, 'energy_term': -0.0317703779388386, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -635.4075587767719, 'abs_comfort_penalty': 0, 'total_power_demand': 635.4075587767719, 'total_temperature_violation': 0.0}\n",
                        "Reward:  -6947.8674909499505 {'time_elapsed(hours)': 7296.25, 'month': 11, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 29185, 'reward': -0.00589738497079933, 'energy_term': -0.00589738497079933, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': 0, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.0}\n",
                        "Reward:  -7262.780547134471 {'time_elapsed(hours)': 8016.25, 'month': 12, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 32065, 'reward': -0.018698130195532896, 'energy_term': -0.018698130195532896, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -373.9626039106579, 'abs_comfort_penalty': 0, 'total_power_demand': 373.9626039106579, 'total_temperature_violation': 0.0}\n",
                        "Progress: |***************************************************************************************************| 99%\n",
                        "Episode  0 Mean reward:  -0.21917652329611786 Cumulative reward:  -7679.94537629597\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# create rule-based controller\n",
                "agent = MyRuleBasedController(env)\n",
                "\n",
                "for i in range(1):\n",
                "    obs, info = env.reset()\n",
                "    rewards = []\n",
                "    truncated = terminated = False\n",
                "    current_month = 0\n",
                "while not (terminated or truncated):\n",
                "    action = agent.act(obs)\n",
                "    obs, reward, terminated, truncated, info = env.step(action)\n",
                "    rewards.append(reward)\n",
                "    if info['month'] != current_month:  # display results every month\n",
                "        current_month = info['month']\n",
                "        print('Reward: ', sum(rewards), info)\n",
                "print(\n",
                "    'Episode ',\n",
                "    i,\n",
                "    'Mean reward: ',\n",
                "    np.mean(rewards),\n",
                "    'Cumulative reward: ',\n",
                "    sum(rewards))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "Always remember to close the environment when you're done:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [5zone-hot-continuous-v1]\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "env.close()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For more information about our defined controllers and how to create a new one, please visit our [Controller Documentation](https://ugr-sail.github.io/sinergym/compilation/main/pages/controllers.html)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.4 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        },
        "vscode": {
            "interpreter": {
                "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
