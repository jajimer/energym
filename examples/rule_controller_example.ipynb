{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "# Rule Controller example"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "First, we import all the necessary libraries. Remember to always import `sinergym`, even if it appears unused, as it's needed to define the environments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "from typing import List, Any, Sequence\n",
                "from sinergym.utils.constants import YEAR\n",
                "from datetime import datetime\n",
                "import gymnasium as gym\n",
                "import numpy as np\n",
                "import sinergym"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "Next, we can define the environment we want to use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "#==============================================================================================#\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: 5zone-hot-continuous-v1\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "#==============================================================================================#\n",
                        "\u001b[38;20m[MODELING] (INFO) : Experiment working directory created.\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Working directory: /workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res1\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Model Config is correct.\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Update building model Output:Variable with variable names.\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Update building model Output:Meter with meter names.\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Runperiod established.\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : timesteps per episode: 35040\u001b[0m\n",
                        "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "env = gym.make('Eplus-5zone-hot-continuous-v1')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "For the Rule-based controller, check out the already defined controllers. There's one for each building. We're extending that controller and defining the action function we want. Feel free to modify the function to define your own action."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "from sinergym.utils.controllers import RBC5Zone\n",
                "\n",
                "class MyRuleBasedController(RBC5Zone):\n",
                "\n",
                "    def act(self, observation: List[Any]) -> Sequence[Any]:\n",
                "        \"\"\"Select action based on outdoor air drybulb temperature and daytime.\n",
                "\n",
                "        Args:\n",
                "            observation (List[Any]): Perceived observation.\n",
                "\n",
                "        Returns:\n",
                "            Sequence[Any]: Action chosen.\n",
                "        \"\"\"\n",
                "        obs_dict = dict(zip(self.env.get_wrapper_attr('observation_variables'), observation))\n",
                "\n",
                "        out_temp = obs_dict['outdoor_temperature']\n",
                "\n",
                "        day = int(obs_dict['day_of_month'])\n",
                "        month = int(obs_dict['month'])\n",
                "        hour = int(obs_dict['hour'])\n",
                "        year = int(obs_dict['year'] if obs_dict.get('year',False) else YEAR)\n",
                "\n",
                "        summer_start_date = datetime(year, 6, 1)\n",
                "        summer_final_date = datetime(year, 9, 30)\n",
                "\n",
                "        current_dt = datetime(year, month, day)\n",
                "\n",
                "        # Get season comfort range\n",
                "        if current_dt >= summer_start_date and current_dt <= summer_final_date:\n",
                "            season_comfort_range = self.setpoints_summer\n",
                "        else:\n",
                "            season_comfort_range = self.setpoints_summer\n",
                "        season_comfort_range = self.setpoints_winter\n",
                "        # Update setpoints\n",
                "        in_temp = obs_dict['air_temperature']\n",
                "\n",
                "        current_heat_setpoint = obs_dict[\n",
                "            'htg_setpoint']\n",
                "        current_cool_setpoint = obs_dict[\n",
                "            'clg_setpoint']\n",
                "\n",
                "        new_heat_setpoint = current_heat_setpoint\n",
                "        new_cool_setpoint = current_cool_setpoint\n",
                "\n",
                "        if in_temp < season_comfort_range[0]:\n",
                "            new_heat_setpoint = current_heat_setpoint + 1\n",
                "            new_cool_setpoint = current_cool_setpoint + 1\n",
                "        elif in_temp > season_comfort_range[1]:\n",
                "            new_cool_setpoint = current_cool_setpoint - 1\n",
                "            new_heat_setpoint = current_heat_setpoint - 1\n",
                "\n",
                "        #Clip setpoints to the action space\n",
                "        if new_heat_setpoint>self.env.get_wrapper_attr('action_space').high[0]:\n",
                "            new_heat_setpoint=self.env.get_wrapper_attr('action_space').high[0]\n",
                "        if new_heat_setpoint<self.env.get_wrapper_attr('action_space').low[0]:\n",
                "            new_heat_setpoint=self.env.get_wrapper_attr('action_space').low[0]\n",
                "        if new_cool_setpoint>self.env.get_wrapper_attr('action_space').high[1]:\n",
                "            new_cool_setpoint=self.env.get_wrapper_attr('action_space').high[1]\n",
                "        if new_cool_setpoint<self.env.get_wrapper_attr('action_space').low[1]:\n",
                "            new_cool_setpoint=self.env.get_wrapper_attr('action_space').low[1]\n",
                "\n",
                "        action = (new_heat_setpoint, new_cool_setpoint)\n",
                "        if current_dt.weekday() > 5 or hour in range(22, 6):\n",
                "            #weekend or night\n",
                "            action = (18.33, 23.33)\n",
                "\n",
                "        return action"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "Now that our controller is ready, we can use it:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "#----------------------------------------------------------------------------------------------#\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: 5zone-hot-continuous-v1\u001b[0m\n",
                        "#----------------------------------------------------------------------------------------------#\n",
                        "\u001b[38;20m[MODELING] (INFO) : Episode directory created.\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model.\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path.\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
                        "Reward:  -0.10122987987606541 {'time_elapsed(hours)': 0.5, 'month': 1, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(13.8), np.float32(30.0)), 'timestep': 1, 'reward': -0.10122987987606541, 'energy_term': -0.00589738497079933, 'comfort_term': -0.09533249490526607, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': -0.19066498981053215, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.19066498981053215}\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.12/dist-packages/gymnasium/spaces/box.py:240: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
                        "  gym.logger.warn(\"Casting input x to numpy array.\")\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Simulation Progress [Episode 1]:  10%|█         | 10/100 [00:00<00:09,  9.64%/s, 10% completed] Reward:  -500.8158604654543 {'time_elapsed(hours)': 744.25, 'month': 2, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 2976, 'reward': -0.00589738497079933, 'energy_term': -0.00589738497079933, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': 0, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.0}\n",
                        "Simulation Progress [Episode 1]:  17%|█▋        | 17/100 [00:01<00:08,  9.88%/s, 17% completed]Reward:  -771.2477959705227 {'time_elapsed(hours)': 1416.25, 'month': 3, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 5664, 'reward': -0.00589738497079933, 'energy_term': -0.00589738497079933, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': 0, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.0}\n",
                        "Simulation Progress [Episode 1]:  26%|██▌       | 26/100 [00:02<00:06, 11.30%/s, 26% completed]Reward:  -1099.6675505462101 {'time_elapsed(hours)': 2160.25, 'month': 4, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (18.33, 23.33), 'timestep': 8640, 'reward': -0.00589738497079933, 'energy_term': -0.00589738497079933, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': 0, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.0}\n",
                        "Simulation Progress [Episode 1]:  34%|███▍      | 34/100 [00:03<00:06,  9.53%/s, 34% completed]Reward:  -1443.9892728462598 {'time_elapsed(hours)': 2880.25, 'month': 5, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 11520, 'reward': -0.00986244334034497, 'energy_term': -0.00986244334034497, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -197.24886680689937, 'abs_comfort_penalty': 0, 'total_power_demand': 197.24886680689937, 'total_temperature_violation': 0.0}\n",
                        "Simulation Progress [Episode 1]:  42%|████▏     | 42/100 [00:04<00:06,  9.08%/s, 42% completed]Reward:  -1850.3837512878513 {'time_elapsed(hours)': 3624.25, 'month': 6, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 14496, 'reward': -0.443418973577729, 'energy_term': -0.03306759297397215, 'comfort_term': -0.41035138060375687, 'reward_weight': 0.5, 'abs_energy_penalty': -661.351859479443, 'abs_comfort_penalty': -0.8207027612075137, 'total_power_demand': 661.351859479443, 'total_temperature_violation': 0.8207027612075137}\n",
                        "Simulation Progress [Episode 1]:  51%|█████     | 51/100 [00:05<00:04, 11.44%/s, 51% completed]Reward:  -2994.821084822717 {'time_elapsed(hours)': 4344.25, 'month': 7, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (18.33, 23.33), 'timestep': 17376, 'reward': -0.2168368480281406, 'energy_term': -0.03331450494007778, 'comfort_term': -0.1835223430880628, 'reward_weight': 0.5, 'abs_energy_penalty': -666.2900988015556, 'abs_comfort_penalty': -0.3670446861761256, 'total_power_demand': 666.2900988015556, 'total_temperature_violation': 0.3670446861761256}\n",
                        "Simulation Progress [Episode 1]:  59%|█████▉    | 59/100 [00:06<00:04,  8.89%/s, 59% completed]Reward:  -4192.843264700024 {'time_elapsed(hours)': 5088.25, 'month': 8, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 20352, 'reward': -0.4444265580218612, 'energy_term': -0.03655451169123719, 'comfort_term': -0.407872046330624, 'reward_weight': 0.5, 'abs_energy_penalty': -731.0902338247438, 'abs_comfort_penalty': -0.815744092661248, 'total_power_demand': 731.0902338247438, 'total_temperature_violation': 0.815744092661248}\n",
                        "Simulation Progress [Episode 1]:  67%|██████▋   | 67/100 [00:06<00:02, 11.54%/s, 67% completed]Reward:  -5380.941330999556 {'time_elapsed(hours)': 5832.25, 'month': 9, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 23328, 'reward': -0.2973068555116624, 'energy_term': -0.02993733348744081, 'comfort_term': -0.2673695220242216, 'reward_weight': 0.5, 'abs_energy_penalty': -598.7466697488162, 'abs_comfort_penalty': -0.5347390440484432, 'total_power_demand': 598.7466697488162, 'total_temperature_violation': 0.5347390440484432}\n",
                        "Simulation Progress [Episode 1]:  76%|███████▌  | 76/100 [00:07<00:02, 10.25%/s, 76% completed]Reward:  -6627.123778199568 {'time_elapsed(hours)': 6552.25, 'month': 10, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 26208, 'reward': -0.03177037793883851, 'energy_term': -0.03177037793883851, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -635.4075587767702, 'abs_comfort_penalty': 0, 'total_power_demand': 635.4075587767702, 'total_temperature_violation': 0.0}\n",
                        "Simulation Progress [Episode 1]:  84%|████████▍ | 84/100 [00:08<00:01, 11.03%/s, 84% completed]Reward:  -6944.464641871541 {'time_elapsed(hours)': 7296.25, 'month': 11, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 29184, 'reward': -0.00589738497079933, 'energy_term': -0.00589738497079933, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': 0, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.0}\n",
                        "Simulation Progress [Episode 1]:  92%|█████████▏| 92/100 [00:09<00:00, 10.92%/s, 92% completed]Reward:  -7259.377698005483 {'time_elapsed(hours)': 8016.25, 'month': 12, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 32064, 'reward': -0.018698130195533794, 'energy_term': -0.018698130195533794, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -373.96260391067585, 'abs_comfort_penalty': 0, 'total_power_demand': 373.96260391067585, 'total_temperature_violation': 0.0}\n",
                        "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:09<00:00, 11.14%/s, 100% completed]Episode  0 Mean reward:  -0.21907941002188872 Cumulative reward:  -7676.542527166982\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# create rule-based controller\n",
                "agent = MyRuleBasedController(env)\n",
                "\n",
                "for i in range(1):\n",
                "    obs, info = env.reset()\n",
                "    rewards = []\n",
                "    truncated = terminated = False\n",
                "    current_month = 0\n",
                "while not (terminated or truncated):\n",
                "    action = agent.act(obs)\n",
                "    obs, reward, terminated, truncated, info = env.step(action)\n",
                "    rewards.append(reward)\n",
                "    if info['month'] != current_month:  # display results every month\n",
                "        current_month = info['month']\n",
                "        print('Reward: ', sum(rewards), info)\n",
                "print(\n",
                "    'Episode ',\n",
                "    i,\n",
                "    'Mean reward: ',\n",
                "    np.mean(rewards),\n",
                "    'Cumulative reward: ',\n",
                "    sum(rewards))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "Always remember to close the environment when you're done:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:12<00:00,  8.33%/s, 100% completed]\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [5zone-hot-continuous-v1]\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "env.close()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For more information about our defined controllers and how to create a new one, please visit our [Controller Documentation](https://ugr-sail.github.io/sinergym/compilation/main/pages/controllers.html)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.4 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        },
        "vscode": {
            "interpreter": {
                "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
