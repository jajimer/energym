{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "# Basic example"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true,
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "Sinergym uses the standard [Farama Gymnasium API](https://gymnasium.farama.org/index.html). Lets see how to create a basic loop.\n",
                "\n",
                "First, we need to include Sinergym and to create an environment, in our case using `Eplus-demo-v1`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "#==============================================================================================#\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment... [demo-v1]\u001b[0m\n",
                        "#==============================================================================================#\n",
                        "\u001b[38;20m[MODELING] (INFO) : Experiment working directory created [/workspaces/sinergym/examples/Eplus-env-demo-v1-res1]\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : runperiod established: {'start_day': 1, 'start_month': 1, 'start_year': 1991, 'end_day': 31, 'end_month': 12, 'end_year': 1991, 'start_weekday': 1, 'n_steps_per_hour': 4}\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : timesteps per episode: 35040\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Model Config is correct.\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment demo-v1 created successfully.\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "import gymnasium as gym\n",
                "import numpy as np\n",
                "\n",
                "import sinergym\n",
                "env = gym.make('Eplus-demo-v1')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "At first glance, it may appear that Sinergym is only imported, but never used. Importing Sinergym, all its [Environments](https://ugr-sail.github.io/sinergym/compilation/html/pages/environments.html)\n",
                "are defined to be used. In this case, `Eplus-demo-v1` is available with all the features contained.\n",
                "\n",
                "After this simple definition, we are ready to loop the episodes. For this simple example, we are going to consider only 1 episode. In summary, the code which we need is something like this:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "#----------------------------------------------------------------------------------------------#\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode... [Episode 1]\u001b[0m\n",
                        "#----------------------------------------------------------------------------------------------#\n",
                        "\u001b[38;20m[MODELING] (INFO) : Episode directory created [/workspaces/sinergym/examples/Eplus-env-demo-v1-res1/Eplus-env-sub_run1]\u001b[0m\n",
                        "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Variable available names\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path... [/workspaces/sinergym/examples/Eplus-env-demo-v1-res1/Eplus-env-sub_run1/output]\u001b[0m\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/dist-packages/opyplus/weather_data/weather_data.py:493: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
                        "  epw_content = self._headers_to_epw(use_datetimes=use_datetimes) + df.to_csv(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;20m[SIMULATOR] (INFO) : Running EnergyPlus with args: ['-w', '/workspaces/sinergym/examples/Eplus-env-demo-v1-res1/Eplus-env-sub_run1/USA_PA_Pittsburgh-Allegheny.County.AP.725205_TMY3.epw', '-d', '/workspaces/sinergym/examples/Eplus-env-demo-v1-res1/Eplus-env-sub_run1/output', '/workspaces/sinergym/examples/Eplus-env-demo-v1-res1/Eplus-env-sub_run1/5ZoneAutoDXVAV.epJSON']\u001b[0m\n",
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : Handles initialized.\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : Handles are ready.\u001b[0m\n",
                        "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
                        "Reward:  -1.4254385096063296 {'time_elapsed(hours)': 0.75, 'year': 1995, 'month': 1, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [18.540745, 28.084728], 'timestep': 2, 'reward': -1.4254385096063296, 'reward_energy': -0.09759966457086716, 'reward_comfort': -2.753277354641792, 'total_energy': 975.9966457086716, 'abs_comfort': 2.753277354641792, 'temperatures': [17.246722645358208]}\n",
                        "Reward:  -1369.2197847359469 {'time_elapsed(hours)': 744.2916666666666, 'year': 2004, 'month': 2, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [18.048912, 23.24202], 'timestep': 2976, 'reward': -0.13879983228543358, 'reward_energy': -0.27759966457086716, 'reward_comfort': -0.0, 'total_energy': 2775.9966457086716, 'abs_comfort': 0.0, 'temperatures': [20.94143053913133]}\n",
                        "Reward:  -3121.5818268631465 {'time_elapsed(hours)': 1416.3333333333333, 'year': 2000, 'month': 3, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [20.70321, 24.11236], 'timestep': 5664, 'reward': -0.4304559999611765, 'reward_energy': -0.0476985272671676, 'reward_comfort': -0.8132134726551854, 'total_energy': 476.98527267167594, 'abs_comfort': 0.8132134726551854, 'temperatures': [19.186786527344815]}\n",
                        "Reward:  -4817.432184179871 {'time_elapsed(hours)': 2160.3333333333335, 'year': 1991, 'month': 4, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [18.886724, 26.37917], 'timestep': 8640, 'reward': -0.0034341956839029878, 'reward_energy': -0.0068683913678059755, 'reward_comfort': -0.0, 'total_energy': 68.68391367805975, 'abs_comfort': 0.0, 'temperatures': [20.1250083354098]}\n",
                        "Reward:  -6830.4931391804 {'time_elapsed(hours)': 2880.25, 'year': 1996, 'month': 5, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [18.255701, 28.491814], 'timestep': 11520, 'reward': -0.0, 'reward_energy': -0.0, 'reward_comfort': -0.0, 'total_energy': 0.0, 'abs_comfort': 0.0, 'temperatures': [22.099550361450305]}\n",
                        "Reward:  -8891.369958504001 {'time_elapsed(hours)': 3624.25, 'year': 2003, 'month': 6, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [16.891432, 28.060535], 'timestep': 14496, 'reward': -0.0, 'reward_energy': -0.0, 'reward_comfort': -0.0, 'total_energy': 0.0, 'abs_comfort': 0.0, 'temperatures': [23.388148594833684]}\n",
                        "Reward:  -10613.544902375545 {'time_elapsed(hours)': 4344.25, 'year': 2004, 'month': 7, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [19.811148, 29.473894], 'timestep': 17376, 'reward': -0.0, 'reward_energy': -0.0, 'reward_comfort': -0.0, 'total_energy': 0.0, 'abs_comfort': 0.0, 'temperatures': [23.22310697120138]}\n",
                        "Reward:  -12178.826605654973 {'time_elapsed(hours)': 5088.25, 'year': 1994, 'month': 8, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [18.472122, 26.706238], 'timestep': 20352, 'reward': -0.030628211524101445, 'reward_energy': -0.0, 'reward_comfort': -0.06125642304820289, 'total_energy': 0.0, 'abs_comfort': 0.06125642304820289, 'temperatures': [22.938743576951797]}\n",
                        "Reward:  -13711.784653572497 {'time_elapsed(hours)': 5832.25, 'year': 1996, 'month': 9, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [15.052247, 28.259514], 'timestep': 23328, 'reward': -0.31878632879905133, 'reward_energy': -0.0, 'reward_comfort': -0.6375726575981027, 'total_energy': 0.0, 'abs_comfort': 0.6375726575981027, 'temperatures': [22.362427342401897]}\n",
                        "Reward:  -15691.896746976563 {'time_elapsed(hours)': 6552.333333333333, 'year': 1999, 'month': 10, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [21.668655, 22.537306], 'timestep': 26208, 'reward': -0.38977939388862204, 'reward_energy': -0.0, 'reward_comfort': -0.7795587877772441, 'total_energy': 0.0, 'abs_comfort': 0.7795587877772441, 'temperatures': [22.220441212222756]}\n",
                        "Reward:  -17863.08688751622 {'time_elapsed(hours)': 7296.375, 'year': 2004, 'month': 11, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [17.013231, 29.407843], 'timestep': 29184, 'reward': -0.0060932427794117335, 'reward_energy': -0.012186485558823467, 'reward_comfort': -0.0, 'total_energy': 121.86485558823466, 'abs_comfort': 0.0, 'temperatures': [20.352258351173194]}\n",
                        "Reward:  -18935.145464227342 {'time_elapsed(hours)': 8016.3125, 'year': 1997, 'month': 12, 'day': 1, 'hour': 0, 'is_raining': True, 'action': [22.160416, 28.180706], 'timestep': 32064, 'reward': -0.3741989706835282, 'reward_energy': -0.013222958731539714, 'reward_comfort': -0.7351749826355167, 'total_energy': 132.22958731539714, 'abs_comfort': 0.7351749826355167, 'temperatures': [19.264825017364483]}\n",
                        "Progress: |***************************************************************************************************| 99%\n"
                    ]
                }
            ],
            "source": [
                "for i in range(1):\n",
                "    obs, info = env.reset()\n",
                "    rewards = []\n",
                "    terminated = False\n",
                "    current_month = 0\n",
                "    while not terminated:\n",
                "        a = env.action_space.sample()\n",
                "        obs, reward, terminated, truncated, info = env.step(a)\n",
                "        rewards.append(reward)\n",
                "        if info['month'] != current_month:  # display results every month\n",
                "            current_month = info['month']\n",
                "            print('Reward: ', sum(rewards), info)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "And, as always, don't forget to close the environment when the interaction finishes:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed.\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "env.close()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "Now, we can see the final rewards:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mean reward:  -0.5715457603415743 Cumulative reward:  -20026.39189660931\n"
                    ]
                }
            ],
            "source": [
                "print(\n",
                "    'Mean reward: ',\n",
                "    np.mean(rewards),\n",
                "    'Cumulative reward: ',\n",
                "    sum(rewards))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The [list of environments](https://github.com/ugr-sail/sinergym/blob/main/sinergym/__init__.py) that we have registered in Sinergym is extensive and we use buildings files changing particularities. For example, continuous action space or discrete, noise over weather, runperiod, timesteps, reward function, etc. We will see it in the following notebooks."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.4 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        },
        "vscode": {
            "interpreter": {
                "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
