{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Basic example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sinergym uses the standard [Farama Gymnasium API](https://gymnasium.farama.org/index.html). Lets see how to create a basic loop.\n",
    "\n",
    "First, we need to include Sinergym and to create an environment, in our case using `Eplus-demo-v1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment... [demo-v1]\u001b[0m\n",
      "#==============================================================================================#\n",
      "\u001b[38;20m[MODELING] (INFO) : Experiment working directory created [/workspaces/sinergym/examples/Eplus-env-demo-v1-res1]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : runperiod established: {'start_day': 1, 'start_month': 1, 'start_year': 1991, 'end_day': 31, 'end_month': 12, 'end_year': 1991, 'start_weekday': 1, 'n_steps_per_hour': 4}\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timesteps per episode: 35040\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment demo-v1 created successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "import sinergym\n",
    "env = gym.make('Eplus-demo-v1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At first glance, it may appear that Sinergym is only imported, but never used. Importing Sinergym, all its [Environments](https://ugr-sail.github.io/sinergym/compilation/html/pages/environments.html)\n",
    "are defined to be used. In this case, `Eplus-demo-v1` is available with all the features contained.\n",
    "\n",
    "After this simple definition, we are ready to loop the episodes. For this simple example, we are going to consider only 1 episode. In summary, the code which we need is something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode... [demo-v1] [Episode 1]\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode directory created [/workspaces/sinergym/examples/Eplus-env-demo-v1-res1/Eplus-env-sub_run1]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Weather file USA_PA_Pittsburgh-Allegheny.County.AP.725205_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Variable available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Meter available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model. [USA_PA_Pittsburgh-Allegheny.County.AP.725205_TMY3.epw]\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path... [/workspaces/sinergym/examples/Eplus-env-demo-v1-res1/Eplus-env-sub_run1/output]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/opyplus/weather_data/weather_data.py:493: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  epw_content = self._headers_to_epw(use_datetimes=use_datetimes) + df.to_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[SIMULATOR] (INFO) : Running EnergyPlus with args: ['-w', '/workspaces/sinergym/examples/Eplus-env-demo-v1-res1/Eplus-env-sub_run1/USA_PA_Pittsburgh-Allegheny.County.AP.725205_TMY3.epw', '-d', '/workspaces/sinergym/examples/Eplus-env-demo-v1-res1/Eplus-env-sub_run1/output', '/workspaces/sinergym/examples/Eplus-env-demo-v1-res1/Eplus-env-sub_run1/5ZoneAutoDXVAV.epJSON']\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "Reward:  -1.4254385096063296 {'time_elapsed(hours)': 0.5, 'month': 1, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [15.100837, 25.150742], 'timestep': 2, 'reward': -1.4254385096063296, 'energy_term': -0.04879983228543358, 'comfort_term': -1.376638677320896, 'reward_weight': 0.5, 'abs_energy': 975.9966457086716, 'abs_comfort': 2.753277354641792, 'energy_values': [975.9966457086716], 'temp_values': [17.246722645358208]}\n",
      "Reward:  -1368.0176373619688 {'time_elapsed(hours)': 744.3333333333334, 'month': 2, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [18.57318, 28.183784], 'timestep': 2977, 'reward': -1.3450150599212425, 'energy_term': -0.04879983228543358, 'comfort_term': -1.296215227635809, 'reward_weight': 0.5, 'abs_energy': 975.9966457086716, 'abs_comfort': 2.592430455271618, 'energy_values': [975.9966457086716], 'temp_values': [17.407569544728382]}\n",
      "Reward:  -3069.5510896622022 {'time_elapsed(hours)': 1416.375, 'month': 3, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [18.307262, 27.530552], 'timestep': 5665, 'reward': -0.7743806765542438, 'energy_term': -0.027510685009766885, 'comfort_term': -0.746869991544477, 'reward_weight': 0.5, 'abs_energy': 550.2137001953377, 'abs_comfort': 1.493739983088954, 'energy_values': [550.2137001953377], 'temp_values': [18.506260016911046]}\n",
      "Reward:  -4729.6794157687455 {'time_elapsed(hours)': 2160.3125, 'month': 4, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [20.213997, 29.072813], 'timestep': 8641, 'reward': -0.0, 'energy_term': -0.0, 'comfort_term': -0.0, 'reward_weight': 0.5, 'abs_energy': 0.0, 'abs_comfort': 0.0, 'energy_values': [0.0], 'temp_values': [20.118258129866394]}\n",
      "Reward:  -6758.959402072298 {'time_elapsed(hours)': 2880.25, 'month': 5, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [16.328068, 24.981213], 'timestep': 11521, 'reward': -0.0, 'energy_term': -0.0, 'comfort_term': -0.0, 'reward_weight': 0.5, 'abs_energy': 0.0, 'abs_comfort': 0.0, 'energy_values': [0.0], 'temp_values': [21.846054342736416]}\n",
      "Reward:  -8818.952554579948 {'time_elapsed(hours)': 3624.25, 'month': 6, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [15.741652, 23.889093], 'timestep': 14497, 'reward': -0.0, 'energy_term': -0.0, 'comfort_term': -0.0, 'reward_weight': 0.5, 'abs_energy': 0.0, 'abs_comfort': 0.0, 'energy_values': [0.0], 'temp_values': [23.341436722269997]}\n",
      "Reward:  -10528.450507240643 {'time_elapsed(hours)': 4344.25, 'month': 7, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [15.263984, 26.073057], 'timestep': 17377, 'reward': -0.010233171250309425, 'energy_term': -0.0, 'comfort_term': -0.010233171250309425, 'reward_weight': 0.5, 'abs_energy': 0.0, 'abs_comfort': 0.02046634250061885, 'energy_values': [0.0], 'temp_values': [22.97953365749938]}\n",
      "Reward:  -12097.713648961846 {'time_elapsed(hours)': 5088.25, 'month': 8, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [15.554899, 28.204298], 'timestep': 20353, 'reward': -0.08524338182947311, 'energy_term': -0.0, 'comfort_term': -0.08524338182947311, 'reward_weight': 0.5, 'abs_energy': 0.0, 'abs_comfort': 0.17048676365894622, 'energy_values': [0.0], 'temp_values': [22.829513236341054]}\n",
      "Reward:  -13635.72770625519 {'time_elapsed(hours)': 5832.25, 'month': 9, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [18.91902, 22.86194], 'timestep': 23329, 'reward': -0.3484690521837326, 'energy_term': -0.0, 'comfort_term': -0.3484690521837326, 'reward_weight': 0.5, 'abs_energy': 0.0, 'abs_comfort': 0.6969381043674652, 'energy_values': [0.0], 'temp_values': [22.303061895632535]}\n",
      "Reward:  -15602.477855209052 {'time_elapsed(hours)': 6552.333333333333, 'month': 10, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [15.350457, 25.432655], 'timestep': 26209, 'reward': -0.0053368027442205705, 'energy_term': -0.0053368027442205705, 'comfort_term': -0.0, 'reward_weight': 0.5, 'abs_energy': 106.7360548844114, 'abs_comfort': 0.0, 'energy_values': [106.7360548844114], 'temp_values': [21.420256484655116]}\n",
      "Reward:  -17808.496446759378 {'time_elapsed(hours)': 7296.333333333333, 'month': 11, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [19.21159, 26.02683], 'timestep': 29185, 'reward': -0.006591211235136996, 'energy_term': -0.006591211235136996, 'comfort_term': -0.0, 'reward_weight': 0.5, 'abs_energy': 131.8242247027399, 'abs_comfort': 0.0, 'energy_values': [131.8242247027399], 'temp_values': [21.27623326338583]}\n",
      "Reward:  -18893.826731659658 {'time_elapsed(hours)': 8016.333333333333, 'month': 12, 'day': 1, 'hour': 0, 'is_raining': True, 'action': [19.215921, 22.663082], 'timestep': 32065, 'reward': -0.00667665939051511, 'energy_term': -0.00667665939051511, 'comfort_term': -0.0, 'reward_weight': 0.5, 'abs_energy': 133.5331878103022, 'abs_comfort': 0.0, 'energy_values': [133.5331878103022], 'temp_values': [21.649540360548965]}\n",
      "Progress: |***************************************************************************************************| 99%\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    obs, info = env.reset()\n",
    "    rewards = []\n",
    "    terminated = False\n",
    "    current_month = 0\n",
    "    while not terminated:\n",
    "        a = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(a)\n",
    "        rewards.append(reward)\n",
    "        if info['month'] != current_month:  # display results every month\n",
    "            current_month = info['month']\n",
    "            print('Reward: ', sum(rewards), info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And, as always, don't forget to close the environment when the interaction finishes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [demo-v1]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we can see the final rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward:  -0.5717763681790835 Cumulative reward:  -20035.04394099578\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'Mean reward: ',\n",
    "    np.mean(rewards),\n",
    "    'Cumulative reward: ',\n",
    "    sum(rewards))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [list of environments](https://github.com/ugr-sail/sinergym/blob/main/sinergym/__init__.py) that we have registered in Sinergym is extensive and we use buildings files changing particularities. For example, continuous or discrete action spaces, different types of weathers, noise over weather, runperiod, timesteps, reward functions, etc. We will see it in the following notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
